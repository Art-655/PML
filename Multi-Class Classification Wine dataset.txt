import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
from imblearn.over_sampling import SMOTE

df = pd.read_csv('wine.csv')

df.head()

df['class'].value_counts()

df.shape

X = df.drop('class', axis=1)
y = df['class']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)
# Stratify ensures that the class distribution is maintained in both training and test sets.

scaler = StandardScaler()
X_train, X_test = scaler.fit_transform(X_train), scaler.transform(X_test)

print(pd.DataFrame(X_train).head())

X_train_res, y_train_res = SMOTE(random_state=42).fit_resample(X_train, y_train)

y_train_res.value_counts()

lr = LogisticRegression(max_iter=5000, multi_class='multinomial')

lr.fit(X_train_res, y_train_res)

print("Logistic Regression \n", classification_report(y_test, lr.predict(X_test)))

rf = RandomForestClassifier(class_weight='balanced', random_state=42)

rf.fit(X_train_res, y_train_res)